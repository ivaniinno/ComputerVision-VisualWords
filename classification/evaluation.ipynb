{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4998126c",
   "metadata": {},
   "source": [
    "# Evaluation of Multi-label Baselines on BoVW Features\n",
    "\n",
    "This notebook trains and evaluates multiple baselines for multi-label genre classification on precomputed BoVW features. It performs per-class threshold tuning on a validation split, applies calibration where needed, produces confusion-style per-class summaries, and aggregates a unified results table.\n",
    "\n",
    "Data:\n",
    "- CSV: data/dataset2.csv (metadata and genre labels)\n",
    "- NPZ: data/bovw_vectors_kmeans_1000.npz (bovw_vectors, kmeans_centers, filenames)\n",
    "\n",
    "Outline:\n",
    "1) Load data and align features/labels by filename\n",
    "2) Evaluation utilities: F1 (micro/macro), Jaccard, Hamming, mAP, ROC-AUC, LRAP, top-k\n",
    "3) Confusion-style utilities: per-class TP/FP/FN/TN and micro totals\n",
    "4) Validation split and per-class threshold tuning by F1\n",
    "5) Models: LinearSVC (raw, calibrated), SGD(log), Ridge (raw, calibrated), Logistic (saga), scikit-learn MLP, PyTorch MLP, improved Torch BigMLP; optionally XGBoost (OVR)\n",
    "6) Unified summary and artifact saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c2f44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:10:37.662307Z",
     "iopub.status.busy": "2025-11-09T16:10:37.662015Z",
     "iopub.status.idle": "2025-11-09T16:10:40.033883Z",
     "shell.execute_reply": "2025-11-09T16:10:40.033004Z",
     "shell.execute_reply.started": "2025-11-09T16:10:37.662287Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV: /kaggle/input/wikiart-sift-pca-uint8/dataset.csv\n",
      "CSV shape: (78204, 33)\n",
      "Loading NPZ: /kaggle/input/wikiart-sift-pca-uint8/bovw_vectors_kmeans_1000.npz\n",
      "BoVW: (79998, 1000) Centers: (1000, 64) Files: 79998\n",
      "Label count per sample: min 1 max 2\n",
      "Train: (63365, 1000) (63365, 27) Test: (14839, 1000) (14839, 27)\n"
     ]
    }
   ],
   "source": [
    "# Load Data and Align Features/Labels\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('/kaggle/input/wikiart-sift-pca-uint8')\n",
    "CSV_PATH = DATA_DIR / 'dataset.csv'\n",
    "NPZ_PATH = DATA_DIR / 'bovw_vectors_kmeans_1000.npz'\n",
    "\n",
    "print('Loading CSV:', CSV_PATH)\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print('CSV shape:', df.shape)\n",
    "\n",
    "print('Loading NPZ:', NPZ_PATH)\n",
    "npz = np.load(NPZ_PATH, allow_pickle=True)\n",
    "X_bovw = npz['bovw_vectors']\n",
    "centers = npz['kmeans_centers']\n",
    "filenames_npz = npz['filenames'].astype(str)\n",
    "print('BoVW:', X_bovw.shape, 'Centers:', centers.shape, 'Files:', len(filenames_npz))\n",
    "\n",
    "# Build labels\n",
    "NON_LABEL_COLS = {'Unnamed: 0','filename','width','height','genre_count','subset'}\n",
    "label_cols = [c for c in df.columns if c not in NON_LABEL_COLS]\n",
    "Y_all = df[label_cols].astype(int).values\n",
    "\n",
    "# Sanity checks\n",
    "label_counts = Y_all.sum(axis=1)\n",
    "print('Label count per sample: min', label_counts.min(), 'max', label_counts.max())\n",
    "assert label_counts.min() >= 1 and label_counts.max() <= 2\n",
    "\n",
    "# Align features order by filename\n",
    "fname_to_idx = {fn: i for i, fn in enumerate(filenames_npz)}\n",
    "indices = df['filename'].map(fname_to_idx)\n",
    "assert indices.isna().sum() == 0, 'CSV filenames not found in NPZ.'\n",
    "X_all = X_bovw[indices.astype(int).values]\n",
    "\n",
    "# Train/Test split from CSV\n",
    "is_train = df['subset'].str.lower().eq('train').values\n",
    "is_test = df['subset'].str.lower().eq('test').values\n",
    "X_train, Y_train = X_all[is_train], Y_all[is_train]\n",
    "X_test, Y_test = X_all[is_test], Y_all[is_test]\n",
    "print('Train:', X_train.shape, Y_train.shape, 'Test:', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df68a9f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:10:45.238453Z",
     "iopub.status.busy": "2025-11-09T16:10:45.237589Z",
     "iopub.status.idle": "2025-11-09T16:10:45.834931Z",
     "shell.execute_reply": "2025-11-09T16:10:45.833712Z",
     "shell.execute_reply.started": "2025-11-09T16:10:45.238425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation Utilities (metrics, mAP, ROC, LRAP)\n",
    "from sklearn.metrics import (\n",
    "    f1_score, jaccard_score, hamming_loss,\n",
    "    average_precision_score, roc_auc_score,\n",
    "    label_ranking_average_precision_score, coverage_error, label_ranking_loss\n",
    ")\n",
    "\n",
    "def evaluate_multilabel(Y_true, scores, threshold=0.5, label_names=None):\n",
    "    Y_pred = (scores >= threshold).astype(int)\n",
    "    metrics = {\n",
    "        'f1_micro': f1_score(Y_true, Y_pred, average='micro', zero_division=0),\n",
    "        'f1_macro': f1_score(Y_true, Y_pred, average='macro', zero_division=0),\n",
    "        'jaccard_micro': jaccard_score(Y_true, Y_pred, average='micro', zero_division=0),\n",
    "        'hamming_loss': hamming_loss(Y_true, Y_pred),\n",
    "    }\n",
    "    try:\n",
    "        ap_per_class = average_precision_score(Y_true, scores, average=None)\n",
    "        metrics['mAP_macro'] = float(np.nanmean(ap_per_class))\n",
    "    except Exception:\n",
    "        ap_per_class = np.full(Y_true.shape[1], np.nan)\n",
    "        metrics['mAP_macro'] = np.nan\n",
    "    try:\n",
    "        metrics['roc_auc_micro'] = roc_auc_score(Y_true, scores, average='micro')\n",
    "        metrics['roc_auc_macro'] = roc_auc_score(Y_true, scores, average='macro')\n",
    "    except Exception:\n",
    "        metrics['roc_auc_micro'] = np.nan\n",
    "        metrics['roc_auc_macro'] = np.nan\n",
    "    try:\n",
    "        metrics['lrap'] = label_ranking_average_precision_score(Y_true, scores)\n",
    "        metrics['coverage_error'] = coverage_error(Y_true, scores)\n",
    "        metrics['label_ranking_loss'] = label_ranking_loss(Y_true, scores)\n",
    "    except Exception:\n",
    "        metrics['lrap'] = np.nan\n",
    "        metrics['coverage_error'] = np.nan\n",
    "        metrics['label_ranking_loss'] = np.nan\n",
    "\n",
    "    if label_names is None:\n",
    "        label_names = [f'class_{i}' for i in range(Y_true.shape[1])]\n",
    "    ap_df = pd.DataFrame({'label': label_names, 'AP': ap_per_class})\n",
    "    ap_df = ap_df.sort_values('AP', ascending=False, na_position='last').reset_index(drop=True)\n",
    "    return metrics, ap_df, Y_pred\n",
    "\n",
    "# Ranking/top-k utility\n",
    "\n",
    "def topk_multilabel_accuracy(Y_true, scores, k):\n",
    "    idx = np.argsort(-scores, axis=1)[:, :k]\n",
    "    hits = []\n",
    "    Y_true_bool = (Y_true == 1)\n",
    "    for i in range(Y_true.shape[0]):\n",
    "        hits.append(Y_true_bool[i, idx[i]].any())\n",
    "    return float(np.mean(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914ad4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:10:48.112565Z",
     "iopub.status.busy": "2025-11-09T16:10:48.112121Z",
     "iopub.status.idle": "2025-11-09T16:10:48.122545Z",
     "shell.execute_reply": "2025-11-09T16:10:48.121666Z",
     "shell.execute_reply.started": "2025-11-09T16:10:48.112540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Confusion-Matrix Style Utilities for Multilabel\n",
    "from sklearn.metrics import multilabel_confusion_matrix, precision_score, recall_score\n",
    "\n",
    "\n",
    "def per_class_confusion(Y_true, Y_pred, label_names):\n",
    "    mcm = multilabel_confusion_matrix(Y_true, Y_pred)\n",
    "    rows = []\n",
    "    for j, cm in enumerate(mcm):\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        support = int((Y_true[:, j] == 1).sum())\n",
    "        prec = precision_score(Y_true[:, j], Y_pred[:, j], zero_division=0)\n",
    "        rec = recall_score(Y_true[:, j], Y_pred[:, j], zero_division=0)\n",
    "        f1 = 0.0 if (prec + rec) == 0 else 2 * prec * rec / (prec + rec)\n",
    "        rows.append({\n",
    "            'label': label_names[j], 'TP': int(tp), 'FP': int(fp), 'FN': int(fn), 'TN': int(tn),\n",
    "            'precision': float(prec), 'recall': float(rec), 'f1': float(f1), 'support': support\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values('f1', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def micro_confusion_totals(Y_true, Y_pred):\n",
    "    mcm = multilabel_confusion_matrix(Y_true, Y_pred)\n",
    "    tn = mcm[:, 0, 0].sum()\n",
    "    fp = mcm[:, 0, 1].sum()\n",
    "    fn = mcm[:, 1, 0].sum()\n",
    "    tp = mcm[:, 1, 1].sum()\n",
    "    return {'TP': int(tp), 'FP': int(fp), 'FN': int(fn), 'TN': int(tn)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0e5a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:10:48.586768Z",
     "iopub.status.busy": "2025-11-09T16:10:48.586496Z",
     "iopub.status.idle": "2025-11-09T16:10:48.821086Z",
     "shell.execute_reply": "2025-11-09T16:10:48.820219Z",
     "shell.execute_reply.started": "2025-11-09T16:10:48.586750Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-train: (53860, 1000) Validation: (9505, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Validation Split for Per-Class Threshold Tuning\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratify by number of labels (1 vs 2)\n",
    "label_counts_train = Y_train.sum(axis=1)\n",
    "strata = (label_counts_train >= 2).astype(int)\n",
    "X_tr, X_val, Y_tr, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.15, random_state=42, stratify=strata\n",
    ")\n",
    "\n",
    "print('Sub-train:', X_tr.shape, 'Validation:', X_val.shape)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def tune_thresholds_by_f1(Y_true, scores, min_pos=1):\n",
    "    n_classes = Y_true.shape[1]\n",
    "    thresholds = np.zeros(n_classes, dtype=float)\n",
    "    f1_best = np.full(n_classes, np.nan)\n",
    "    for j in range(n_classes):\n",
    "        y = Y_true[:, j]\n",
    "        s = scores[:, j]\n",
    "        if y.sum() < min_pos:\n",
    "            thresholds[j] = 0.5\n",
    "            f1_best[j] = np.nan\n",
    "            continue\n",
    "        p, r, t = precision_recall_curve(y, s)\n",
    "        f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
    "        idx = int(np.nanargmax(f1))\n",
    "        thr = 0.5 if idx == 0 else t[idx - 1]\n",
    "        thresholds[j] = thr\n",
    "        f1_best[j] = f1[idx]\n",
    "    return thresholds, f1_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f4057d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:10:51.473048Z",
     "iopub.status.busy": "2025-11-09T16:10:51.472373Z",
     "iopub.status.idle": "2025-11-09T16:10:51.479102Z",
     "shell.execute_reply": "2025-11-09T16:10:51.478267Z",
     "shell.execute_reply.started": "2025-11-09T16:10:51.473012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Helper to evaluate a model given validation/test scores\n",
    "\n",
    "def evaluate_with_thresholds(Y_val, scores_val, Y_test, scores_test, label_names, model_name, extras=None):\n",
    "    thr, f1_val = tune_thresholds_by_f1(Y_val, scores_val)\n",
    "    # metrics on test with tuned thresholds\n",
    "    metrics, ap_df, Y_pred = evaluate_multilabel(Y_test, scores_test, threshold=thr.reshape(1, -1), label_names=label_names)\n",
    "    per_cls_df = per_class_confusion(Y_test, Y_pred, label_names)\n",
    "    micro_totals = micro_confusion_totals(Y_test, Y_pred)\n",
    "    topk = {\n",
    "        'top1_acc': topk_multilabel_accuracy(Y_test, scores_test, k=1),\n",
    "        'top2_acc': topk_multilabel_accuracy(Y_test, scores_test, k=2),\n",
    "        'top3_acc': topk_multilabel_accuracy(Y_test, scores_test, k=3),\n",
    "    }\n",
    "    out = {\n",
    "        'model': model_name,\n",
    "        'metrics': metrics,\n",
    "        'ap': ap_df,\n",
    "        'per_class': per_cls_df.assign(threshold=thr),\n",
    "        'micro_totals': micro_totals,\n",
    "        'topk': topk,\n",
    "        'thresholds': thr,\n",
    "    }\n",
    "    if extras:\n",
    "        out.update(extras)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2d0fb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:10:53.348403Z",
     "iopub.status.busy": "2025-11-09T16:10:53.348021Z",
     "iopub.status.idle": "2025-11-09T16:29:30.665164Z",
     "shell.execute_reply": "2025-11-09T16:29:30.664311Z",
     "shell.execute_reply.started": "2025-11-09T16:10:53.348353Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC raw done in 368.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC calibrated done in 731.1s\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC OVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, Normalizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Raw LinearSVC \n",
    "svm_raw = Pipeline([\n",
    "    ('scale', MaxAbsScaler()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(C=1.0, class_weight='balanced', dual=False, random_state=42), n_jobs=-1))\n",
    "])\n",
    "start = time.time()\n",
    "svm_raw.fit(X_tr, Y_tr)\n",
    "train_time = time.time() - start\n",
    "val_scores_raw = svm_raw.named_steps['clf'].decision_function(svm_raw.named_steps['scale'].transform(X_val))\n",
    "test_scores_raw = svm_raw.named_steps['clf'].decision_function(svm_raw.named_steps['scale'].transform(X_test))\n",
    "res_raw = evaluate_with_thresholds(Y_val, val_scores_raw, Y_test, test_scores_raw, label_cols, 'LinearSVC_raw', extras={'train_time_sec': train_time, 'calibrated': False})\n",
    "results['LinearSVC_raw'] = res_raw\n",
    "print('LinearSVC raw done in {:.1f}s'.format(train_time))\n",
    "\n",
    "# Calibrated LinearSVC \n",
    "lsvc = LinearSVC(C=1.0, class_weight='balanced', dual=False, random_state=42)\n",
    "try:\n",
    "    calibrated_base = CalibratedClassifierCV(estimator=lsvc, method='sigmoid', cv=3)\n",
    "except TypeError:\n",
    "    calibrated_base = CalibratedClassifierCV(base_estimator=lsvc, method='sigmoid', cv=3)\n",
    "svm_cal = Pipeline([\n",
    "    ('scale', MaxAbsScaler()),\n",
    "    ('clf', OneVsRestClassifier(calibrated_base, n_jobs=-1))\n",
    "])\n",
    "start = time.time()\n",
    "svm_cal.fit(X_tr, Y_tr)\n",
    "train_time = time.time() - start\n",
    "val_proba_cal = svm_cal.predict_proba(X_val)\n",
    "test_proba_cal = svm_cal.predict_proba(X_test)\n",
    "res_cal = evaluate_with_thresholds(Y_val, val_proba_cal, Y_test, test_proba_cal, label_cols, 'LinearSVC_calibrated', extras={'train_time_sec': train_time, 'calibrated': True})\n",
    "results['LinearSVC_calibrated'] = res_cal\n",
    "print('LinearSVC calibrated done in {:.1f}s'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694ca65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:29:30.667138Z",
     "iopub.status.busy": "2025-11-09T16:29:30.666698Z",
     "iopub.status.idle": "2025-11-09T16:29:56.805033Z",
     "shell.execute_reply": "2025-11-09T16:29:56.804019Z",
     "shell.execute_reply.started": "2025-11-09T16:29:30.667116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD(log) done in 19.6s\n"
     ]
    }
   ],
   "source": [
    "# SGDClassifier(log) OVR\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sigmoid = lambda x: 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "sgd = Pipeline([\n",
    "    ('scale', MaxAbsScaler()),\n",
    "    ('clf', OneVsRestClassifier(SGDClassifier(loss='log_loss', alpha=1e-4, max_iter=20, tol=1e-3, random_state=42), n_jobs=-1))\n",
    "])\n",
    "start = time.time()\n",
    "sgd.fit(X_tr, Y_tr)\n",
    "train_time = time.time() - start\n",
    "val_margins = sgd.named_steps['clf'].decision_function(sgd.named_steps['scale'].transform(X_val))\n",
    "val_probas = sigmoid(val_margins)\n",
    "test_margins = sgd.named_steps['clf'].decision_function(sgd.named_steps['scale'].transform(X_test))\n",
    "test_probas = sigmoid(test_margins)\n",
    "res_sgd = evaluate_with_thresholds(Y_val, val_probas, Y_test, test_probas, label_cols, 'SGD_log_OVR', extras={'train_time_sec': train_time, 'calibrated': False})\n",
    "results['SGD_log_OVR'] = res_sgd\n",
    "print('SGD(log) done in {:.1f}s'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ce9d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:29:56.806665Z",
     "iopub.status.busy": "2025-11-09T16:29:56.806212Z",
     "iopub.status.idle": "2025-11-09T16:31:03.996878Z",
     "shell.execute_reply": "2025-11-09T16:31:03.995964Z",
     "shell.execute_reply.started": "2025-11-09T16:29:56.806633Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge raw done in 17.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge calibrated done in 39.2s\n"
     ]
    }
   ],
   "source": [
    "# RidgeClassifier OVR (raw + calibrated)\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge_raw = Pipeline([\n",
    "    ('scale', MaxAbsScaler()),\n",
    "    ('clf', OneVsRestClassifier(RidgeClassifier(alpha=1.0, class_weight='balanced', random_state=42), n_jobs=-1))\n",
    "])\n",
    "start = time.time()\n",
    "ridge_raw.fit(X_tr, Y_tr)\n",
    "train_time = time.time() - start\n",
    "val_scores_ridge = ridge_raw.named_steps['clf'].decision_function(ridge_raw.named_steps['scale'].transform(X_val))\n",
    "test_scores_ridge = ridge_raw.named_steps['clf'].decision_function(ridge_raw.named_steps['scale'].transform(X_test))\n",
    "res_ridge_raw = evaluate_with_thresholds(Y_val, val_scores_ridge, Y_test, test_scores_ridge, label_cols, 'Ridge_OVR_raw', extras={'train_time_sec': train_time, 'calibrated': False})\n",
    "results['Ridge_OVR_raw'] = res_ridge_raw\n",
    "print('Ridge raw done in {:.1f}s'.format(train_time))\n",
    "\n",
    "# Calibrated Ridge via CalibratedClassifierCV \n",
    "ridge_base = RidgeClassifier(alpha=1.0, class_weight='balanced', random_state=42)\n",
    "try:\n",
    "    ridge_cal_base = CalibratedClassifierCV(estimator=ridge_base, method='sigmoid', cv=3)\n",
    "except TypeError:\n",
    "    ridge_cal_base = CalibratedClassifierCV(base_estimator=ridge_base, method='sigmoid', cv=3)\n",
    "\n",
    "ridge_cal = Pipeline([\n",
    "    ('scale', MaxAbsScaler()),\n",
    "    ('clf', OneVsRestClassifier(ridge_cal_base, n_jobs=-1))\n",
    "])\n",
    "start = time.time()\n",
    "ridge_cal.fit(X_tr, Y_tr)\n",
    "train_time = time.time() - start\n",
    "val_proba_ridge_cal = ridge_cal.predict_proba(X_val)\n",
    "test_proba_ridge_cal = ridge_cal.predict_proba(X_test)\n",
    "res_ridge_cal = evaluate_with_thresholds(Y_val, val_proba_ridge_cal, Y_test, test_proba_ridge_cal, label_cols, 'Ridge_OVR_calibrated', extras={'train_time_sec': train_time, 'calibrated': True})\n",
    "results['Ridge_OVR_calibrated'] = res_ridge_cal\n",
    "print('Ridge calibrated done in {:.1f}s'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9967970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:31:03.999060Z",
     "iopub.status.busy": "2025-11-09T16:31:03.998775Z",
     "iopub.status.idle": "2025-11-09T16:45:23.991939Z",
     "shell.execute_reply": "2025-11-09T16:45:23.991103Z",
     "shell.execute_reply.started": "2025-11-09T16:31:03.999041Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(saga) done in 855.0s\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression(saga) OVR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([\n",
    "    ('l2norm', Normalizer(norm='l2')),\n",
    "    ('scale', MaxAbsScaler()),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(solver='saga', C=1.0, class_weight='balanced', penalty='l2', max_iter=100, n_jobs=-1, random_state=42), n_jobs=-1))\n",
    "])\n",
    "start = time.time()\n",
    "logreg.fit(X_tr, Y_tr)\n",
    "train_time = time.time() - start\n",
    "val_proba_logreg = logreg.predict_proba(X_val)\n",
    "test_proba_logreg = logreg.predict_proba(X_test)\n",
    "res_logreg = evaluate_with_thresholds(Y_val, val_proba_logreg, Y_test, test_proba_logreg, label_cols, 'LogReg_saga_OVR', extras={'train_time_sec': train_time, 'calibrated': False})\n",
    "results['LogReg_saga_OVR'] = res_logreg\n",
    "print('LogisticRegression(saga) done in {:.1f}s'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d0280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:57:41.874711Z",
     "iopub.status.busy": "2025-11-09T16:57:41.874445Z",
     "iopub.status.idle": "2025-11-09T16:58:45.406928Z",
     "shell.execute_reply": "2025-11-09T16:58:45.405856Z",
     "shell.execute_reply.started": "2025-11-09T16:57:41.874692Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(sklearn) done in 58.7s\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn MLP \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = Pipeline([\n",
    "    ('scale', MaxAbsScaler()),\n",
    "    ('clf', MLPClassifier(hidden_layer_sizes=(512,256), activation='relu', alpha=1e-4, batch_size=512,\n",
    "                          learning_rate_init=1e-3, max_iter=40, early_stopping=True, n_iter_no_change=3,\n",
    "                          random_state=42, verbose=False))\n",
    "])\n",
    "start = time.time()\n",
    "mlp.fit(X_tr, Y_tr)\n",
    "train_time = time.time() - start\n",
    "proba_val = mlp.named_steps['clf'].predict_proba(mlp.named_steps['scale'].transform(X_val))\n",
    "if isinstance(proba_val, list):\n",
    "    proba_val = np.column_stack([p[:,1] for p in proba_val])\n",
    "proba_test = mlp.named_steps['clf'].predict_proba(mlp.named_steps['scale'].transform(X_test))\n",
    "if isinstance(proba_test, list):\n",
    "    proba_test = np.column_stack([p[:,1] for p in proba_test])\n",
    "res_mlp = evaluate_with_thresholds(Y_val, proba_val, Y_test, proba_test, label_cols, 'MLP_sklearn', extras={'train_time_sec': train_time, 'calibrated': False})\n",
    "results['MLP_sklearn'] = res_mlp\n",
    "print('MLP(sklearn) done in {:.1f}s'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b40558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T16:45:59.636431Z",
     "iopub.status.busy": "2025-11-09T16:45:59.636141Z",
     "iopub.status.idle": "2025-11-09T16:46:15.313398Z",
     "shell.execute_reply": "2025-11-09T16:46:15.312516Z",
     "shell.execute_reply.started": "2025-11-09T16:45:59.636398Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/8 - loss: 1.2325\n",
      "Epoch 2/8 - loss: 1.0675\n",
      "Epoch 3/8 - loss: 0.9883\n",
      "Epoch 4/8 - loss: 0.9382\n",
      "Epoch 5/8 - loss: 0.9032\n",
      "Epoch 6/8 - loss: 0.8771\n",
      "Epoch 7/8 - loss: 0.8602\n",
      "Epoch 8/8 - loss: 0.8410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n",
      "/tmp/ipykernel_48/552171210.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  f1 = np.where((p + r) > 0, 2 * p * r / (p + r), 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch MLP done in 5.6s\n"
     ]
    }
   ],
   "source": [
    "# PyTorch MLP \n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    torch_available = True\n",
    "except Exception as e:\n",
    "    print('PyTorch not available')\n",
    "    torch_available = False\n",
    "\n",
    "if torch_available:\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print('Using device:', device)\n",
    "\n",
    "    Xtr_t = torch.from_numpy(X_tr.astype(np.float32))\n",
    "    Ytr_t = torch.from_numpy(Y_tr.astype(np.float32))\n",
    "    Xval_t = torch.from_numpy(X_val.astype(np.float32))\n",
    "    Xte_t = torch.from_numpy(X_test.astype(np.float32))\n",
    "\n",
    "    train_ds = TensorDataset(Xtr_t, Ytr_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=1024, shuffle=True, num_workers=0)\n",
    "\n",
    "    class TorchMLP(nn.Module):\n",
    "        def __init__(self, in_dim=1000, num_classes=27):\n",
    "            super().__init__()\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(in_dim, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "                nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "                nn.Linear(256, num_classes)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "\n",
    "    model = TorchMLP(in_dim=X_tr.shape[1], num_classes=Y_tr.shape[1]).to(device)\n",
    "    pos_counts = Y_tr.sum(axis=0).astype(np.float32)\n",
    "    neg_counts = Y_tr.shape[0] - pos_counts\n",
    "    pos_weight = torch.from_numpy((neg_counts / np.maximum(pos_counts, 1e-6))).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    epochs = 8\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    for ep in range(epochs):\n",
    "        running = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running += loss.item() * xb.size(0)\n",
    "        print(f'Epoch {ep+1}/{epochs} - loss: {running/len(train_loader.dataset):.4f}')\n",
    "    train_time = time.time() - start\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        def batched_logits(Xt, bs=2048):\n",
    "            out = []\n",
    "            for i in range(0, Xt.size(0), bs):\n",
    "                out.append(model(Xt[i:i+bs].to(device)).cpu())\n",
    "            return torch.cat(out, dim=0)\n",
    "        val_logits = batched_logits(Xval_t)\n",
    "        test_logits = batched_logits(Xte_t)\n",
    "        val_proba = torch.sigmoid(val_logits).numpy()\n",
    "        test_proba = torch.sigmoid(test_logits).numpy()\n",
    "\n",
    "    res_torch = evaluate_with_thresholds(Y_val, val_proba, Y_test, test_proba, label_cols, 'Torch_MLP', extras={'train_time_sec': train_time, 'calibrated': False})\n",
    "    results['Torch_MLP'] = res_torch\n",
    "    print('Torch MLP done in {:.1f}s'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa121e16-2c8e-499f-a16a-a7ba42b9af25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T18:42:52.326398Z",
     "iopub.status.busy": "2025-11-09T18:42:52.325692Z",
     "iopub.status.idle": "2025-11-09T18:56:05.851812Z",
     "shell.execute_reply": "2025-11-09T18:56:05.851033Z",
     "shell.execute_reply.started": "2025-11-09T18:42:52.326372Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost OVR (GPU=True)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:44:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:44:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:44:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:44:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:46:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:46:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:46:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:46:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:48:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:48:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:48:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:48:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:50:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:50:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:50:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:50:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:51:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:52:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:52:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:52:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:53:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:54:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:54:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:54:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:55:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:55:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:55:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:55:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost done in 776.4s\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    print(\"Training XGBoost OVR (GPU=%s)...\" % gpu_available)\n",
    "    xgb_base = XGBClassifier(n_estimators=800, learning_rate=0.05,\n",
    "                             use_label_encoder=False,\n",
    "                             tree_method='gpu_hist' if gpu_available else 'hist',\n",
    "                             predictor='gpu_predictor' if gpu_available else 'auto',\n",
    "                             verbosity=0, n_jobs=8)\n",
    "    xgb_ovr = Pipeline([('scale', MaxAbsScaler()), ('clf', OVR(xgb_base, n_jobs=-1))])\n",
    "    t0 = time.time()\n",
    "    xgb_ovr.fit(X_tr, Y_tr)\n",
    "    t_xgb = time.time() - t0\n",
    "    val_proba_xgb = xgb_ovr.predict_proba(X_val)\n",
    "    test_proba_xgb = xgb_ovr.predict_proba(X_test)\n",
    "    res_xgb = evaluate_with_thresholds(Y_val, val_proba_xgb, Y_test, test_proba_xgb, label_cols, 'XGBoost_OVR', extras={'train_time_sec': t_xgb})\n",
    "    results['XGBoost_OVR'] = res_xgb\n",
    "    print('XGBoost done in {:.1f}s'.format(t_xgb))\n",
    "except Exception as e:\n",
    "    print('XGBoost skipped:', e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64b644-4af9-4663-9d8d-838c2b99fed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T18:30:21.462481Z",
     "iopub.status.busy": "2025-11-09T18:30:21.462162Z",
     "iopub.status.idle": "2025-11-09T18:30:45.608379Z",
     "shell.execute_reply": "2025-11-09T18:30:45.607633Z",
     "shell.execute_reply.started": "2025-11-09T18:30:21.462459Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 loss=1.1948 val_loss=1.0762\n",
      "Epoch 2/25 loss=1.0340 val_loss=1.0090\n",
      "Epoch 3/25 loss=0.9642 val_loss=0.9380\n",
      "Epoch 4/25 loss=0.9044 val_loss=0.8902\n",
      "Epoch 5/25 loss=0.8619 val_loss=0.8777\n",
      "Epoch 6/25 loss=0.8308 val_loss=0.8703\n",
      "Epoch 7/25 loss=0.8002 val_loss=0.8706\n",
      "Epoch 8/25 loss=0.7850 val_loss=0.8413\n",
      "Epoch 9/25 loss=0.7679 val_loss=0.8646\n",
      "Epoch 10/25 loss=0.7477 val_loss=0.8608\n",
      "Epoch 11/25 loss=0.7388 val_loss=0.8466\n",
      "Epoch 12/25 loss=0.7047 val_loss=0.8388\n",
      "Epoch 13/25 loss=0.6864 val_loss=0.8444\n",
      "Epoch 14/25 loss=0.6759 val_loss=0.8807\n",
      "Epoch 15/25 loss=0.6674 val_loss=0.8795\n",
      "Epoch 16/25 loss=0.6494 val_loss=0.8714\n",
      "Epoch 17/25 loss=0.6445 val_loss=0.8908\n",
      "Epoch 18/25 loss=0.6346 val_loss=0.8986\n",
      "Epoch 19/25 loss=0.6240 val_loss=0.9179\n",
      "Epoch 20/25 loss=0.6221 val_loss=0.9103\n",
      "Epoch 21/25 loss=0.6169 val_loss=0.9192\n",
      "Epoch 22/25 loss=0.6130 val_loss=0.9304\n",
      "Epoch 23/25 loss=0.6107 val_loss=0.9275\n",
      "Epoch 24/25 loss=0.6089 val_loss=0.9326\n",
      "Epoch 25/25 loss=0.6065 val_loss=0.9384\n",
      "Torch BigMLP done in 19.4s\n"
     ]
    }
   ],
   "source": [
    "# Improved Torch MLP with better architecture and training\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    elif getattr(torch.backends, 'mps', None) is not None and torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print('Torch device:', device)\n",
    "\n",
    "    # Prepare tensors and dataloaders\n",
    "    Xtr_t = torch.from_numpy(X_tr.astype(np.float32))\n",
    "    Ytr_t = torch.from_numpy(Y_tr.astype(np.float32))\n",
    "    Xval_t = torch.from_numpy(X_val.astype(np.float32))\n",
    "    Yval_t = torch.from_numpy(Y_val.astype(np.float32))            \n",
    "    Xte_t = torch.from_numpy(X_test.astype(np.float32))\n",
    "    Yte_t = torch.from_numpy(Y_test.astype(np.float32))          \n",
    "\n",
    "    bs = 1024\n",
    "    train_ds = TensorDataset(Xtr_t, Ytr_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=4 if device.type=='cuda' else 0, pin_memory=(device.type=='cuda'))\n",
    "\n",
    "    class BigMLP(nn.Module):\n",
    "        def __init__(self, in_dim=1000, n_classes=27):\n",
    "            super().__init__()\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(in_dim, 2048), nn.ReLU(), nn.Dropout(0.4),\n",
    "                nn.Linear(2048, 1024), nn.ReLU(), nn.Dropout(0.4),\n",
    "                nn.Linear(1024, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "                nn.Linear(512, n_classes)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "\n",
    "    model = BigMLP(in_dim=X_tr.shape[1], n_classes=Y_tr.shape[1]).to(device)\n",
    "    pos_counts = Y_tr.sum(axis=0).astype(np.float32)\n",
    "    neg_counts = Y_tr.shape[0] - pos_counts\n",
    "    pos_weight = torch.from_numpy((neg_counts / np.maximum(pos_counts, 1e-6))).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2, verbose=False)\n",
    "\n",
    "    # move validation tensors to device \n",
    "    Xval_device = Xval_t.to(device)\n",
    "    Yval_device = Yval_t.to(device)\n",
    "\n",
    "    epochs = 25\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    for ep in range(epochs):\n",
    "        running = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device, non_blocking=(device.type=='cuda'))\n",
    "            yb = yb.to(device, non_blocking=(device.type=='cuda'))\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running += loss.item() * xb.size(0)\n",
    "        # validate for scheduler\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_logits = model(Xval_device)                       \n",
    "            val_loss = float(criterion(val_logits, Yval_device).item())  \n",
    "        scheduler.step(val_loss)\n",
    "        model.train()\n",
    "        print(f'Epoch {ep+1}/{epochs} loss={running/len(train_loader.dataset):.4f} val_loss={val_loss:.4f}')\n",
    "    t_torch = time.time() - t0\n",
    "\n",
    "    # eval \n",
    "    model.eval()\n",
    "    def batched_sigmoid_predict(X_np, bs=2048):\n",
    "        out = []\n",
    "        Xt = torch.from_numpy(X_np.astype(np.float32))\n",
    "        for i in range(0, Xt.size(0), bs):\n",
    "            b = Xt[i:i+bs].to(device)\n",
    "            with torch.no_grad():\n",
    "                out.append(torch.sigmoid(model(b)).cpu())\n",
    "        return torch.cat(out, dim=0).numpy()\n",
    "\n",
    "    val_proba_big = batched_sigmoid_predict(X_val)\n",
    "    test_proba_big = batched_sigmoid_predict(X_test)\n",
    "\n",
    "    res_big = evaluate_with_thresholds(Y_val, val_proba_big, Y_test, test_proba_big, label_cols, 'Torch_BigMLP', extras={'train_time_sec': t_torch})\n",
    "    results['Torch_BigMLP'] = res_big\n",
    "    print('Torch BigMLP done in {:.1f}s'.format(t_torch))\n",
    "except Exception as e:\n",
    "    print('Improved Torch MLP skipped:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fc518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T19:29:42.678644Z",
     "iopub.status.busy": "2025-11-09T19:29:42.677715Z",
     "iopub.status.idle": "2025-11-09T19:29:42.703785Z",
     "shell.execute_reply": "2025-11-09T19:29:42.702900Z",
     "shell.execute_reply.started": "2025-11-09T19:29:42.678605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>jaccard_micro</th>\n",
       "      <th>hamming_loss</th>\n",
       "      <th>mAP_macro</th>\n",
       "      <th>roc_auc_micro</th>\n",
       "      <th>roc_auc_macro</th>\n",
       "      <th>lrap</th>\n",
       "      <th>coverage_error</th>\n",
       "      <th>label_ranking_loss</th>\n",
       "      <th>top1_acc</th>\n",
       "      <th>top2_acc</th>\n",
       "      <th>top3_acc</th>\n",
       "      <th>calibrated</th>\n",
       "      <th>train_time_sec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost_OVR</th>\n",
       "      <td>0.363049</td>\n",
       "      <td>0.326968</td>\n",
       "      <td>0.221784</td>\n",
       "      <td>0.058599</td>\n",
       "      <td>0.305768</td>\n",
       "      <td>0.892879</td>\n",
       "      <td>0.871754</td>\n",
       "      <td>0.523127</td>\n",
       "      <td>4.020824</td>\n",
       "      <td>0.114426</td>\n",
       "      <td>0.344295</td>\n",
       "      <td>0.514118</td>\n",
       "      <td>0.623829</td>\n",
       "      <td>False</td>\n",
       "      <td>776.354267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP_sklearn</th>\n",
       "      <td>0.356916</td>\n",
       "      <td>0.319454</td>\n",
       "      <td>0.217224</td>\n",
       "      <td>0.059236</td>\n",
       "      <td>0.288211</td>\n",
       "      <td>0.892415</td>\n",
       "      <td>0.869138</td>\n",
       "      <td>0.519476</td>\n",
       "      <td>4.034167</td>\n",
       "      <td>0.114977</td>\n",
       "      <td>0.336411</td>\n",
       "      <td>0.510547</td>\n",
       "      <td>0.622616</td>\n",
       "      <td>False</td>\n",
       "      <td>58.681356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_log_OVR</th>\n",
       "      <td>0.331819</td>\n",
       "      <td>0.297997</td>\n",
       "      <td>0.198911</td>\n",
       "      <td>0.065730</td>\n",
       "      <td>0.249041</td>\n",
       "      <td>0.887448</td>\n",
       "      <td>0.852059</td>\n",
       "      <td>0.504990</td>\n",
       "      <td>4.112946</td>\n",
       "      <td>0.118062</td>\n",
       "      <td>0.318283</td>\n",
       "      <td>0.491610</td>\n",
       "      <td>0.608869</td>\n",
       "      <td>False</td>\n",
       "      <td>19.560748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Torch_BigMLP</th>\n",
       "      <td>0.330274</td>\n",
       "      <td>0.300509</td>\n",
       "      <td>0.197801</td>\n",
       "      <td>0.073580</td>\n",
       "      <td>0.244508</td>\n",
       "      <td>0.880271</td>\n",
       "      <td>0.873534</td>\n",
       "      <td>0.459033</td>\n",
       "      <td>4.305681</td>\n",
       "      <td>0.125673</td>\n",
       "      <td>0.257025</td>\n",
       "      <td>0.439854</td>\n",
       "      <td>0.566615</td>\n",
       "      <td>False</td>\n",
       "      <td>19.390507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge_OVR_calibrated</th>\n",
       "      <td>0.311096</td>\n",
       "      <td>0.269048</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.073532</td>\n",
       "      <td>0.210998</td>\n",
       "      <td>0.881392</td>\n",
       "      <td>0.836462</td>\n",
       "      <td>0.488774</td>\n",
       "      <td>4.266527</td>\n",
       "      <td>0.123850</td>\n",
       "      <td>0.299279</td>\n",
       "      <td>0.473549</td>\n",
       "      <td>0.591617</td>\n",
       "      <td>True</td>\n",
       "      <td>39.181445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC_calibrated</th>\n",
       "      <td>0.307533</td>\n",
       "      <td>0.255514</td>\n",
       "      <td>0.181707</td>\n",
       "      <td>0.071880</td>\n",
       "      <td>0.202766</td>\n",
       "      <td>0.877844</td>\n",
       "      <td>0.833300</td>\n",
       "      <td>0.483159</td>\n",
       "      <td>4.339848</td>\n",
       "      <td>0.126643</td>\n",
       "      <td>0.294090</td>\n",
       "      <td>0.465463</td>\n",
       "      <td>0.585956</td>\n",
       "      <td>True</td>\n",
       "      <td>731.073826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge_OVR_raw</th>\n",
       "      <td>0.306017</td>\n",
       "      <td>0.261162</td>\n",
       "      <td>0.180650</td>\n",
       "      <td>0.073028</td>\n",
       "      <td>0.205482</td>\n",
       "      <td>0.849896</td>\n",
       "      <td>0.834689</td>\n",
       "      <td>0.445342</td>\n",
       "      <td>5.067929</td>\n",
       "      <td>0.154426</td>\n",
       "      <td>0.261001</td>\n",
       "      <td>0.419233</td>\n",
       "      <td>0.533459</td>\n",
       "      <td>False</td>\n",
       "      <td>16.964864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC_raw</th>\n",
       "      <td>0.300429</td>\n",
       "      <td>0.245187</td>\n",
       "      <td>0.176767</td>\n",
       "      <td>0.074521</td>\n",
       "      <td>0.190402</td>\n",
       "      <td>0.861454</td>\n",
       "      <td>0.829804</td>\n",
       "      <td>0.439118</td>\n",
       "      <td>4.714873</td>\n",
       "      <td>0.141058</td>\n",
       "      <td>0.244289</td>\n",
       "      <td>0.406833</td>\n",
       "      <td>0.534672</td>\n",
       "      <td>False</td>\n",
       "      <td>368.510962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Torch_MLP</th>\n",
       "      <td>0.289545</td>\n",
       "      <td>0.255508</td>\n",
       "      <td>0.169280</td>\n",
       "      <td>0.079088</td>\n",
       "      <td>0.193293</td>\n",
       "      <td>0.837108</td>\n",
       "      <td>0.846803</td>\n",
       "      <td>0.398863</td>\n",
       "      <td>5.319563</td>\n",
       "      <td>0.164432</td>\n",
       "      <td>0.203046</td>\n",
       "      <td>0.365793</td>\n",
       "      <td>0.483321</td>\n",
       "      <td>False</td>\n",
       "      <td>5.570176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_saga_OVR</th>\n",
       "      <td>0.266077</td>\n",
       "      <td>0.229103</td>\n",
       "      <td>0.153454</td>\n",
       "      <td>0.091895</td>\n",
       "      <td>0.162454</td>\n",
       "      <td>0.820685</td>\n",
       "      <td>0.820585</td>\n",
       "      <td>0.297821</td>\n",
       "      <td>5.733338</td>\n",
       "      <td>0.180191</td>\n",
       "      <td>0.087877</td>\n",
       "      <td>0.216120</td>\n",
       "      <td>0.354943</td>\n",
       "      <td>False</td>\n",
       "      <td>855.012480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      f1_micro  f1_macro  jaccard_micro  hamming_loss  \\\n",
       "model                                                                   \n",
       "XGBoost_OVR           0.363049  0.326968       0.221784      0.058599   \n",
       "MLP_sklearn           0.356916  0.319454       0.217224      0.059236   \n",
       "SGD_log_OVR           0.331819  0.297997       0.198911      0.065730   \n",
       "Torch_BigMLP          0.330274  0.300509       0.197801      0.073580   \n",
       "Ridge_OVR_calibrated  0.311096  0.269048       0.184200      0.073532   \n",
       "LinearSVC_calibrated  0.307533  0.255514       0.181707      0.071880   \n",
       "Ridge_OVR_raw         0.306017  0.261162       0.180650      0.073028   \n",
       "LinearSVC_raw         0.300429  0.245187       0.176767      0.074521   \n",
       "Torch_MLP             0.289545  0.255508       0.169280      0.079088   \n",
       "LogReg_saga_OVR       0.266077  0.229103       0.153454      0.091895   \n",
       "\n",
       "                      mAP_macro  roc_auc_micro  roc_auc_macro      lrap  \\\n",
       "model                                                                     \n",
       "XGBoost_OVR            0.305768       0.892879       0.871754  0.523127   \n",
       "MLP_sklearn            0.288211       0.892415       0.869138  0.519476   \n",
       "SGD_log_OVR            0.249041       0.887448       0.852059  0.504990   \n",
       "Torch_BigMLP           0.244508       0.880271       0.873534  0.459033   \n",
       "Ridge_OVR_calibrated   0.210998       0.881392       0.836462  0.488774   \n",
       "LinearSVC_calibrated   0.202766       0.877844       0.833300  0.483159   \n",
       "Ridge_OVR_raw          0.205482       0.849896       0.834689  0.445342   \n",
       "LinearSVC_raw          0.190402       0.861454       0.829804  0.439118   \n",
       "Torch_MLP              0.193293       0.837108       0.846803  0.398863   \n",
       "LogReg_saga_OVR        0.162454       0.820685       0.820585  0.297821   \n",
       "\n",
       "                      coverage_error  label_ranking_loss  top1_acc  top2_acc  \\\n",
       "model                                                                          \n",
       "XGBoost_OVR                 4.020824            0.114426  0.344295  0.514118   \n",
       "MLP_sklearn                 4.034167            0.114977  0.336411  0.510547   \n",
       "SGD_log_OVR                 4.112946            0.118062  0.318283  0.491610   \n",
       "Torch_BigMLP                4.305681            0.125673  0.257025  0.439854   \n",
       "Ridge_OVR_calibrated        4.266527            0.123850  0.299279  0.473549   \n",
       "LinearSVC_calibrated        4.339848            0.126643  0.294090  0.465463   \n",
       "Ridge_OVR_raw               5.067929            0.154426  0.261001  0.419233   \n",
       "LinearSVC_raw               4.714873            0.141058  0.244289  0.406833   \n",
       "Torch_MLP                   5.319563            0.164432  0.203046  0.365793   \n",
       "LogReg_saga_OVR             5.733338            0.180191  0.087877  0.216120   \n",
       "\n",
       "                      top3_acc  calibrated  train_time_sec  \n",
       "model                                                       \n",
       "XGBoost_OVR           0.623829       False      776.354267  \n",
       "MLP_sklearn           0.622616       False       58.681356  \n",
       "SGD_log_OVR           0.608869       False       19.560748  \n",
       "Torch_BigMLP          0.566615       False       19.390507  \n",
       "Ridge_OVR_calibrated  0.591617        True       39.181445  \n",
       "LinearSVC_calibrated  0.585956        True      731.073826  \n",
       "Ridge_OVR_raw         0.533459       False       16.964864  \n",
       "LinearSVC_raw         0.534672       False      368.510962  \n",
       "Torch_MLP             0.483321       False        5.570176  \n",
       "LogReg_saga_OVR       0.354943       False      855.012480  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary across models\n",
    "import pandas as pd\n",
    "\n",
    "summary_rows = []\n",
    "for name, res in results.items():\n",
    "    m = res['metrics']\n",
    "    topk = res.get('topk', {})\n",
    "    row = {\n",
    "        'model': name,\n",
    "        'f1_micro': m.get('f1_micro'),\n",
    "        'f1_macro': m.get('f1_macro'),\n",
    "        'jaccard_micro': m.get('jaccard_micro'),\n",
    "        'hamming_loss': m.get('hamming_loss'),\n",
    "        'mAP_macro': m.get('mAP_macro'),\n",
    "        'roc_auc_micro': m.get('roc_auc_micro'),\n",
    "        'roc_auc_macro': m.get('roc_auc_macro'),\n",
    "        'lrap': m.get('lrap'),\n",
    "        'coverage_error': m.get('coverage_error'),\n",
    "        'label_ranking_loss': m.get('label_ranking_loss'),\n",
    "        'top1_acc': topk.get('top1_acc'),\n",
    "        'top2_acc': topk.get('top2_acc'),\n",
    "        'top3_acc': topk.get('top3_acc'),\n",
    "        'calibrated': res.get('calibrated', False),\n",
    "        'train_time_sec': res.get('train_time_sec', None),\n",
    "    }\n",
    "    summary_rows.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).set_index('model').sort_values('f1_micro', ascending=False)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54720ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8679604,
     "sourceId": 13653528,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
